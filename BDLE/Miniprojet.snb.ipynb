{
  "metadata" : {
    "id" : "b3014f52-d363-4eb2-85ac-858b8b9d92bc",
    "name" : "Miniprojet",
    "user_save_timestamp" : "1970-01-01T01:00:00.000Z",
    "auto_save_timestamp" : "1970-01-01T01:00:00.000Z",
    "language_info" : {
      "name" : "scala",
      "file_extension" : "scala",
      "codemirror_mode" : "text/x-scala"
    },
    "trusted" : true,
    "sparkNotebook" : null,
    "customLocalRepo" : null,
    "customRepos" : null,
    "customDeps" : null,
    "customImports" : null,
    "customArgs" : null,
    "customSparkConf" : null,
    "customVars" : null
  },
  "cells" : [
    {
      "metadata" : {
        "id" : "4530ADB7AE50422F8329BDDF5E8F1D89"
      },
      "cell_type" : "markdown",
      "source" : "# Partie principale   \n\nDatasets à utiliser : Yago\n\n## Statistiques de base\n\n* Retourner la liste des 10 propriétés les plus fréquentes. La sortie doit être une liste de couples (prop, freq) triée de manière décroissante.\n"
    },
    {
      "metadata" : {
        "trusted" : true,
        "input_collapsed" : false,
        "collapsed" : false,
        "id" : "02E0EF8038DF4EC599208DB19F9F40A0"
      },
      "cell_type" : "code",
      "source" : [
        "case class Triple(sujet: String, prop: String, objet: String)\n",
        "\n",
        "val yagoFile = \"/tmp/BDLE/dataset/yagoFacts5M.txt\""
      ],
      "outputs" : [
        {
          "name" : "stdout",
          "output_type" : "stream",
          "text" : "defined class Triple\nyagoFile: String = /tmp/BDLE/dataset/yagoFacts5M.txt\n"
        },
        {
          "metadata" : { },
          "data" : {
            "text/html" : ""
          },
          "output_type" : "execute_result",
          "execution_count" : 1,
          "time" : "Took: 0.956s, at 2017-10-30 14:53"
        }
      ]
    },
    {
      "metadata" : {
        "trusted" : true,
        "input_collapsed" : false,
        "collapsed" : false,
        "id" : "DBFB5BEC81E1453887B0F7B309E0B5DD"
      },
      "cell_type" : "code",
      "source" : [
        "val yago = sc.textFile(yagoFile).\n",
        "  map(ligne => ligne.split(\"\\\\t\")).coalesce(8).\n",
        "  map(tab => Triple(tab(0), tab(1), tab(2))).toDS()\n",
        "\n",
        "yago.persist\n",
        "yago.count\n",
        "yago.show(5)"
      ],
      "outputs" : [
        {
          "name" : "stdout",
          "output_type" : "stream",
          "text" : "+------------+----------------+--------------------+\n|       sujet|            prop|               objet|\n+------------+----------------+--------------------+\n|    <!PAUS3>|     <hasGender>|              <male>|\n|    <!PAUS3>|<hasMusicalRole>|<wordnet_bass_104...|\n|    <!PAUS3>|   <isCitizenOf>|           <Ukraine>|\n|    <!PAUS3>|     <wasBornIn>|      <Philadelphia>|\n|<!T.O.O.H.!>|     <hasGender>|              <male>|\n+------------+----------------+--------------------+\nonly showing top 5 rows\n\nyago: org.apache.spark.sql.Dataset[Triple] = [sujet: string, prop: string ... 1 more field]\n"
        },
        {
          "metadata" : { },
          "data" : {
            "text/html" : ""
          },
          "output_type" : "execute_result",
          "execution_count" : 2,
          "time" : "Took: 7.473s, at 2017-10-30 14:54"
        }
      ]
    },
    {
      "metadata" : {
        "trusted" : true,
        "input_collapsed" : false,
        "collapsed" : false,
        "id" : "E8E056A00D4945E7A000B824FE72BD6A"
      },
      "cell_type" : "code",
      "source" : [
        "val props = yago.groupBy(\"prop\").count.sort($\"count\".desc).limit(10)\n",
        "\n",
        "props.show()"
      ],
      "outputs" : [
        {
          "name" : "stdout",
          "output_type" : "stream",
          "text" : "+----------------+-------+\n|            prop|  count|\n+----------------+-------+\n|<isAffiliatedTo>|1116512|\n|      <playsFor>| 772092|\n|   <isCitizenOf>| 731207|\n|   <isLocatedIn>| 512925|\n|     <hasGender>| 486528|\n|     <wasBornIn>| 405252|\n|       <actedIn>| 242436|\n|        <diedIn>| 131001|\n|   <hasWonPrize>| 115476|\n| <graduatedFrom>| 112670|\n+----------------+-------+\n\nprops: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [prop: string, count: bigint]\n"
        },
        {
          "metadata" : { },
          "data" : {
            "text/html" : ""
          },
          "output_type" : "execute_result",
          "execution_count" : 4,
          "time" : "Took: 1.692s, at 2017-10-30 14:54"
        }
      ]
    },
    {
      "metadata" : {
        "id" : "EE5C93BB363849E99789813498DB7438"
      },
      "cell_type" : "markdown",
      "source" : "* Retourner la liste des 10 noeuds ayant le plus grand degré sortant. Rappel Le degré sortant d'un noeud n est le nombre de triplets où n est le sujet. La sortie doit être une liste de couples (sujet, degré) triée de manière décroissante."
    },
    {
      "metadata" : {
        "trusted" : true,
        "input_collapsed" : false,
        "collapsed" : false,
        "presentation" : {
          "tabs_state" : "{\n  \"tab_id\": \"#tab1507470001-0\"\n}",
          "pivot_chart_state" : "{\n  \"hiddenAttributes\": [],\n  \"menuLimit\": 200,\n  \"cols\": [],\n  \"rows\": [],\n  \"vals\": [],\n  \"exclusions\": {},\n  \"inclusions\": {},\n  \"unusedAttrsVertical\": 85,\n  \"autoSortUnusedAttrs\": false,\n  \"inclusionsInfo\": {},\n  \"aggregatorName\": \"Count\",\n  \"rendererName\": \"Table\"\n}"
        },
        "id" : "1EFA0C13C21248B0853A462BBD28ED2A"
      },
      "cell_type" : "code",
      "source" : [
        "val noeudsDegres = yago.groupBy(\"sujet\").count.sort($\"count\".desc).limit(10)\n",
        "noeudsDegres.show()"
      ],
      "outputs" : [
        {
          "name" : "stdout",
          "output_type" : "stream",
          "text" : "+--------------------+-----+\n|               sujet|count|\n+--------------------+-----+\n|       <Ilaiyaraaja>|  878|\n|        <Prem_Nazir>|  471|\n|     <United_States>|  456|\n|   <Deva_(composer)>|  440|\n|       <Adoor_Bhasi>|  383|\n| <M._S._Viswanathan>|  378|\n|         <Mammootty>|  360|\n|    <United_Kingdom>|  345|\n|<Laxmikant–Pyarelal>|  324|\n|          <Mohanlal>|  314|\n+--------------------+-----+\n\nnoeudsDegres: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [sujet: string, count: bigint]\n"
        },
        {
          "metadata" : { },
          "data" : {
            "text/html" : ""
          },
          "output_type" : "execute_result",
          "execution_count" : 5,
          "time" : "Took: 2.349s, at 2017-10-30 14:54"
        }
      ]
    },
    {
      "metadata" : {
        "id" : "D9A791E89A3E419182F69CAE87E4F03F"
      },
      "cell_type" : "markdown",
      "source" : "* Pour chaque propriété, retourner le nombre de sujets distincts d'où elle démarre ainsi que le nombre d'objets distincts où elle arrive. La sortie doit être une liste de tuples (pro, nb-sujets, nb-objets). Attention Un objet (sujet) peut avoir plusieurs fois la même propriété."
    },
    {
      "metadata" : {
        "trusted" : true,
        "input_collapsed" : false,
        "collapsed" : false,
        "id" : "F3C334067D7D48B8922B070ABC14E7B5"
      },
      "cell_type" : "code",
      "source" : [
        "val propSujets = yago.groupBy(\"prop\", \"sujet\").count.groupBy(\"prop\").count.withColumnRenamed(\"count\", \"nbSujet\")\n",
        "propSujets.show(5)\n",
        "\n",
        "val propObjets = yago.groupBy(\"prop\", \"objet\").count.groupBy(\"prop\").count.withColumnRenamed(\"count\", \"nbObjet\")\n",
        "propObjets.show(5)\n",
        "\n",
        "val propStats = propSujets.join(propObjets, \"prop\")\n",
        "propStats.show(5)"
      ],
      "outputs" : [
        {
          "name" : "stdout",
          "output_type" : "stream",
          "text" : "+--------------------+-------+\n|                prop|nbSujet|\n+--------------------+-------+\n|<hasOfficialLangu...|   1177|\n|    <isInterestedIn>|    781|\n|         <dealsWith>|    262|\n|       <isLocatedIn>| 114649|\n|<hasAcademicAdvisor>|   2318|\n+--------------------+-------+\nonly showing top 5 rows\n\n+--------------------+-------+\n|                prop|nbObjet|\n+--------------------+-------+\n|<hasOfficialLangu...|    134|\n|    <isInterestedIn>|    160|\n|         <dealsWith>|    204|\n|       <isLocatedIn>|  30544|\n|<hasAcademicAdvisor>|    527|\n+--------------------+-------+\nonly showing top 5 rows\n\n+--------------------+-------+-------+\n|                prop|nbSujet|nbObjet|\n+--------------------+-------+-------+\n|<hasOfficialLangu...|   1177|    134|\n|    <isInterestedIn>|    781|    160|\n|         <dealsWith>|    262|    204|\n|       <isLocatedIn>| 114649|  30544|\n|<hasAcademicAdvisor>|   2318|    527|\n+--------------------+-------+-------+\nonly showing top 5 rows\n\npropSujets: org.apache.spark.sql.DataFrame = [prop: string, nbSujet: bigint]\npropObjets: org.apache.spark.sql.DataFrame = [prop: string, nbObjet: bigint]\npropStats: org.apache.spark.sql.DataFrame = [prop: string, nbSujet: bigint ... 1 more field]\n"
        },
        {
          "metadata" : { },
          "data" : {
            "text/html" : ""
          },
          "output_type" : "execute_result",
          "execution_count" : 18,
          "time" : "Took: 5.315s, at 2017-10-30 15:03"
        }
      ]
    },
    {
      "metadata" : {
        "id" : "662E245C23AB44E09A347292BF52AC19"
      },
      "cell_type" : "markdown",
      "source" : "* Encoder la fonction noeudDegre(d:entier) qui retourne les noeuds de degrée d. Le degré d'un noeud = degré sortant + degré entrant."
    },
    {
      "metadata" : {
        "trusted" : true,
        "input_collapsed" : false,
        "collapsed" : false,
        "id" : "6462CDBBA003410C87F17B3DFA776F59"
      },
      "cell_type" : "code",
      "source" : [
        "\n",
        "def noeudDegre(d: Int) : org.apache.spark.sql.Dataset[org.apache.spark.sql.Row]  = {\n",
        "  val noeudsDegres = yago.groupBy(\"sujet\").count.sort($\"count\".desc).limit(10)\n",
        "  noeudsDegres.where(\"count = \"+d.toString)\n",
        "}\n",
        "\n",
        "noeudDegre(112670).show(5)\n"
      ],
      "outputs" : [
        {
          "name" : "stdout",
          "output_type" : "stream",
          "text" : "+-----+-----+\n|sujet|count|\n+-----+-----+\n+-----+-----+\n\nnoeudDegre: (d: Int)org.apache.spark.sql.Dataset[org.apache.spark.sql.Row]\n"
        },
        {
          "metadata" : { },
          "data" : {
            "text/html" : ""
          },
          "output_type" : "execute_result",
          "execution_count" : 25,
          "time" : "Took: 1.115s, at 2017-10-30 15:15"
        }
      ]
    }
  ],
  "nbformat" : 4
}