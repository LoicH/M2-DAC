{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# TME 3 - RÃ©gularisation L1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of X: (569, 30)\n",
      "shape of Y: (569,)\n",
      "classes in Y:  [0 1]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "from sklearn import metrics\n",
    "from sklearn.utils import shuffle\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "cancer = datasets.load_breast_cancer()\n",
    "X = cancer.data\n",
    "print(\"shape of X:\", X.shape)\n",
    "y = cancer.target\n",
    "print(\"shape of Y:\", y.shape)\n",
    "print(\"classes in Y: \", np.unique(y))\n",
    "X, y = shuffle(X, y)\n",
    "\n",
    "# Restricting data\n",
    "X = X[:100,:10]\n",
    "y = y[:100]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "########### Gradient printing: ###########\n",
      "=== Iteration 0 ===\n",
      "Theta init:    [-0.45  0.49 -0.22 ..., -0.46  0.08 -0.14]\n",
      "Gradient:      [ 0.    0.01  0.01 ...,  0.    0.01  0.01]\n",
      "=== Iteration 1 ===\n",
      "Theta init:    [-0.32 -0.45  0.42 ..., -0.25 -0.42  0.49]\n",
      "Gradient:      [ 0.    0.    0.01 ...,  0.01  0.    0.01]\n",
      "=== Iteration 2 ===\n",
      "Theta init:    [-0.34  0.14  0.18 ...,  0.02 -0.25 -0.15]\n",
      "Gradient:      [ 0.    0.01  0.01 ...,  0.01  0.    0.01]\n",
      "=== Iteration 3 ===\n",
      "Theta init:    [-0.44 -0.37  0.2  ..., -0.39  0.01  0.3 ]\n",
      "Gradient:      [ 0.    0.   -0.47 ...,  0.    0.01  0.01]\n",
      "=== Iteration 4 ===\n",
      "Theta init:    [ 0.42  0.26  0.24 ...,  0.26  0.31 -0.12]\n",
      "Gradient:      [ 0.01  0.01  0.01 ...,  0.01  0.01  0.01]\n",
      "=== Iteration 5 ===\n",
      "Theta init:    [-0.47  0.45  0.33 ...,  0.35  0.38 -0.03]\n",
      "Gradient:      [ 0.    0.01 -0.05 ...,  0.01  0.01  0.01]\n",
      "=== Iteration 6 ===\n",
      "Theta init:    [ 0.29 -0.17  0.36 ..., -0.33 -0.17  0.27]\n",
      "Gradient:      [ 0.01  0.01  0.01 ...,  0.    0.01  0.01]\n",
      "=== Iteration 7 ===\n",
      "Theta init:    [-0.42  0.05 -0.34 ..., -0.37 -0.42 -0.28]\n",
      "Gradient:      [ 0.    0.01  0.   ...,  0.    0.    0.  ]\n",
      "=== Iteration 8 ===\n",
      "Theta init:    [ 0.28 -0.41 -0.06 ...,  0.02 -0.04 -0.03]\n",
      "Gradient:      [ 0.01  0.    0.01 ...,  0.01  0.01  0.01]\n",
      "=== Iteration 9 ===\n",
      "Theta init:    [-0.11  0.02  0.03 ..., -0.3   0.5   0.21]\n",
      "Gradient:      [ 0.01  0.01 -0.48 ...,  0.    0.01  0.01]\n"
     ]
    }
   ],
   "source": [
    "from scipy.optimize import approx_fprime, check_grad, minimize\n",
    "\n",
    "def decision(theta, X):\n",
    "    return np.sign(X.dot(theta)) / 2 + 0.5\n",
    "\n",
    "def loss(theta, X, y, pen):\n",
    "    mse = ((y - decision(theta, X))**2).mean()\n",
    "    return mse + pen * np.linalg.norm(theta, 1)\n",
    "\n",
    "print(\"########### Gradient printing: ###########\")\n",
    "for i in range(10):\n",
    "    print(\"=== Iteration %d ===\" % i)\n",
    "    theta_init = np.random.random(X[0].shape) - 0.5\n",
    "    func = lambda t: loss(t, X, y, pen)\n",
    "    grad = approx_fprime(theta_init, func, epsilon=1)\n",
    "    print(\"Theta init:   \", theta_init)\n",
    "    print(\"Gradient:     \",grad)\n",
    "\n",
    "    \n",
    "def gradient_l1(theta, X, y, max_iter=100, step=1e-1, pen=0.1, verbose=0, plot=False):\n",
    "    \"\"\" Performs gradient clipping to find the best theta\n",
    "    :param:\n",
    "    \n",
    "    :return:\"\"\"\n",
    "    \n",
    "    (l, n) = X.shape\n",
    "    losses = []\n",
    "    for it in range(max_iter):\n",
    "        if verbose >= 1:\n",
    "            print(\"###########  Step\", it, \": #################\")\n",
    "        for i in range(l):\n",
    "            idx = np.random.randint(0, l)\n",
    "            if verbose >= 2:\n",
    "                print(\"========= i = %d, idx = %d ===========\" % (i, idx))\n",
    "            local_loss = lambda t: loss(t, np.array([X[idx]]), np.array([y[idx]]), pen)\n",
    "            grad = approx_fprime(theta, local_loss, epsilon=step)\n",
    "            theta_prime = theta - step * grad\n",
    "            \n",
    "            if verbose >= 2:\n",
    "                print(\"Random sample:\", X[idx])\n",
    "                print(\"Gradient:     \",grad)\n",
    "                print(\"Theta before: \", theta)\n",
    "            theta_prime[theta * theta_prime < 0] = 0\n",
    "            theta = theta_prime\n",
    "            if verbose >= 2:\n",
    "                print(\"Theta after:  \", theta)\n",
    "                \n",
    "        general_loss = loss(theta, X, y, pen)\n",
    "        losses.append(general_loss)\n",
    "        if verbose >= 1:\n",
    "            print(\"L = %f\" % (general_loss))\n",
    "    \n",
    "    if plot:\n",
    "        plt.plot(losses)\n",
    "        plt.title(\"Evolution of loss\")\n",
    "        plt.xlabel(\"Iterations\")\n",
    "        plt.ylabel(\"Loss\")\n",
    "    return theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "theta found with gradient descent: [-0.   -0.   -0.01 ..., -0.01 -0.   -0.  ]\n",
      "Decision function: [ 0.  0.  0. ...,  0.  0.  0.]\n",
      "Real labels: [0 0 1 ..., 0 0 1]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEWCAYAAACXGLsWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSFIKCxERSUphISIiSSksREQkqf8PIW9wqOs9R6kAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fc3254d5f98>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Optimization parameters\n",
    "theta_init = np.random.random(X[0].shape)\n",
    "max_iter = 1000\n",
    "step     = 1e-2\n",
    "pen      = 1e-2\n",
    "\n",
    "# Find theta \n",
    "np.set_printoptions(precision=2, threshold=5)\n",
    "theta = gradient_l1(theta_init, X, y, max_iter=max_iter, step=step, pen=pen, verbose=0, plot=True)\n",
    "print(\"theta found with gradient descent:\", theta)\n",
    "# theta_minimize = minimize(lambda t:loss(t, X, y, pen), theta_init).x\n",
    "# print(\"theta with minimize():            \", theta_minimize)\n",
    "print(\"Decision function:\", decision(theta, X))\n",
    "print(\"Real labels:\", y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator\n",
    "\n",
    "class LinearClassifier(BaseEstimator):\n",
    "    \"\"\" Custom linear classifier \"\"\"\n",
    "    \n",
    "    def __init__(self, max_iter=1000, step=1e-2, pen=1e-2, verbose=0):\n",
    "        self.theta= 0\n",
    "        self.max_iter = max_iter\n",
    "        self.step = step\n",
    "        self.pen = pen\n",
    "        self.verbose = verbose\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        self.theta = gradient_l1(np.ones_like(X[0]), X, y, \n",
    "                                 max_iter=self.max_iter, \n",
    "                                 step=self.step, \n",
    "                                 pen=self.pen,\n",
    "                                 verbose=self.verbose)\n",
    "        \n",
    "    def predict(self, X):\n",
    "        return decision(theta, X)\n",
    "\n",
    "    def get_theta(self):\n",
    "        return self.theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Theta found: [-0.2508 -0.2508 -0.2508 -0.2508 -0.005  -0.005  -0.005  -0.005  -0.005\n",
      " -0.005 ]\n",
      "KFold:\n",
      "theta :  [-0.2508 -0.2508 -0.2508 -0.2508 -0.005  -0.005  -0.005  -0.005  -0.005\n",
      " -0.005 ]\n",
      "Y_Pred:  [ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "  1.  1.  1.  1.  1.  1.  1.]\n",
      "Y_reel:  [1 1 1 0 1 1 1 1 1 1 1 1 0 1 1 1 1 0 0 0 1 0 0 1 1]\n",
      "Score:  0.72\n",
      "Errors:  [0 0 0 0 0 0 0]\n",
      "Theta found: [-0.005      -0.005      -0.005      -0.25117647 -0.005      -0.005      -0.005\n",
      " -0.005      -0.005      -0.005     ]\n",
      "KFold:\n",
      "theta :  [-0.005      -0.005      -0.005      -0.25117647 -0.005      -0.005      -0.005\n",
      " -0.005      -0.005      -0.005     ]\n",
      "Y_Pred:  [ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "  1.  1.  1.  1.  1.  1.  1.]\n",
      "Y_reel:  [0 1 1 0 0 1 1 1 0 1 1 1 0 1 1 1 1 1 1 1 1 0 0 1 1]\n",
      "Score:  0.72\n",
      "Errors:  [0 0 0 0 0 0 0]\n",
      "Theta found: [-0.005      -0.005      -0.005      -0.49293746 -0.005      -0.005      -0.005\n",
      " -0.005      -0.005      -0.005     ]\n",
      "KFold:\n",
      "theta :  [-0.005      -0.005      -0.005      -0.49293746 -0.005      -0.005      -0.005\n",
      " -0.005      -0.005      -0.005     ]\n",
      "Y_Pred:  [ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "  1.  1.  1.  1.  1.  1.  1.]\n",
      "Y_reel:  [1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1]\n",
      "Score:  0.92\n",
      "Errors:  [0 0]\n",
      "Theta found: [-0.005  -0.005  -0.005   0.4924 -0.005  -0.005  -0.005  -0.005  -0.005\n",
      " -0.005 ]\n",
      "KFold:\n",
      "theta :  [-0.005  -0.005  -0.005   0.4924 -0.005  -0.005  -0.005  -0.005  -0.005\n",
      " -0.005 ]\n",
      "Y_Pred:  [ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "  1.  1.  1.  1.  1.  1.  1.]\n",
      "Y_reel:  [0 0 0 0 1 1 1 0 1 1 1 0 1 1 0 0 0 1 0 0 1 0 1 1 0]\n",
      "Score:  0.48\n",
      "Errors:  [0 0 0 0 0 0 0 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "\n",
    "\n",
    "kf = KFold(n_splits=4)\n",
    "\n",
    "\n",
    "for train_index, test_index in kf.split(X):\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    Y_train, Y_test = y[train_index], y[test_index]\n",
    "    clf = LinearClassifier(max_iter=max_iter, step=step, pen=pen, verbose=0)\n",
    "    clf.fit(X_train, Y_train)\n",
    "    print(\"Theta found:\", clf.get_theta())\n",
    "    pred = clf.predict(X_test)\n",
    "    \n",
    "    print(\"KFold:\")\n",
    "    print(\"Y_Pred: \", pred)\n",
    "    print(\"Y_reel: \", Y_test)\n",
    "    print(\"Score: \", accuracy_score(pred, Y_test))\n",
    "    print(\"Errors: \", Y_test[pred != Y_test])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
